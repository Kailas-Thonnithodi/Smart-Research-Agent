{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad619d2e",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4996df11",
   "metadata": {},
   "source": [
    "## Agentic Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d9ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, WebSearchTool, trace, Runner, gen_trace_id, function_tool, OpenAIChatCompletionsModel, input_guardrail, GuardrailFunctionOutput\n",
    "from openai import AsyncOpenAI\n",
    "from agents.model_settings import ModelSettings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb997c",
   "metadata": {},
   "source": [
    "## Exterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0944e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import asyncio\n",
    "import sendgrid\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707982f0",
   "metadata": {},
   "source": [
    "## Interior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae28614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import Dict\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b958ddfa",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c081ac3",
   "metadata": {},
   "source": [
    "## Loading in Gemini and OpenAI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "359099a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "load_dotenv(override=True)\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "# Gemini\n",
    "gemini = {\n",
    "    \"base_model\": \"gemini-2.0-flash\",\n",
    "    \"api_key\": os.getenv(\"GEMINI_API_KEY\"),\n",
    "    \"base_url\": \"https://generativelanguage.googleapis.com/v1beta\"\n",
    "}\n",
    "\n",
    "gemini_client = AsyncOpenAI(base_url=gemini[\"base_url\"], api_key=gemini[\"api_key\"])\n",
    "gemini_model = OpenAIChatCompletionsModel(model=gemini[\"base_model\"], openai_client=gemini_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9a049",
   "metadata": {},
   "source": [
    "## Development Summary\n",
    "* OpenAI Agents SDK includes some hosted tools, these include:\\\n",
    "WebSearchTool --> Allows an agent to search the web.\\\n",
    "FileSearchTool --> Allows retrieving information from OpenAI Vector Stores.\\\n",
    "ComputerTool --> Allows automating computer use tasks. These could include taking screenshots, clicking, searching, or other operations, which would require guardrails to limit certain conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f9c433",
   "metadata": {},
   "source": [
    "## Search Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The search agent's instructions parameters values. (these can be changed based on your liking)\n",
    "search_agent_instructions_params = {\n",
    "    \"min_paragraph_count\": 2,\n",
    "    \"max_paragraph_count\": 3,\n",
    "    \"min_word_count\": 200,\n",
    "    \"max_word_count\": 300,\n",
    "    \"tone\": \"semi-formal\"\n",
    "}\n",
    "\n",
    "# Search's dedicated instructions\n",
    "search_agent_instructions = f\" You are a research assistant.\\\n",
    "                Given a search term, you search the web for that term and produce a concise summary of the results.\\\n",
    "                The summary must be {search_agent_instructions_params[\"min_paragraph_count\"]}-{search_agent_instructions_params[\"max_paragraph_count\"]} paragraphs and between than {search_agent_instructions_params[\"min_word_count\"]}-{search_agent_instructions_params[\"max_word_count\"]} words.\\\n",
    "                Capture the main points. Write in a {search_agent_instructions_params[\"tone\"]} tone.\\\n",
    "                This will be consumed by someone synthesizig a report, so it's vital you capture the essense and ignore any fluff.\\\n",
    "                Do not include any additional commentary other than the summary itself.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ac730f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = Agent(\n",
    "    name=\"Search Agent\",\n",
    "    instructions=search_agent_instructions,\n",
    "    # due to the costs of using the websearchtool, i will use the low settings.\n",
    "    tools=[WebSearchTool(search_context_size=\"low\")],\n",
    "    model=gpt_model,\n",
    "    # search agent is expected to run the tool. \n",
    "    model_settings=ModelSettings(tool_choice=\"required\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170571c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_agent_prompt = \"Nvidia's AI innovations of 2025\"\n",
    "\n",
    "with trace(\"Search\"):\n",
    "    result = await Runner.run(search_agent, sample_agent_prompt)\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b6d26",
   "metadata": {},
   "source": [
    "## Planner Agent\n",
    "The overall purpose of the planner agent is to produce x searches which will help the search agent when it's going to do it's searching.\n",
    "No searching is conducted here, however it will be used before the searching, in order help navigate the searching terms before applying the WebSearchTool. \n",
    "* Takes in a query, and then taking in x amount of searches surrounded around the query.\n",
    "* The more queries, the more deeper the research material will be (however this will come at a higher cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f83f7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to costs of SearchTool, I will us 2 for now. \n",
    "SEARCHES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86586d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent_instructions = f\"You are a helpful research assistant. Given a query, come up with a set of web searches to perform to best answer the query.\\\n",
    "                                Output {SEARCHES} terms to query for.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc0413b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WebSearchItem stores the reasoning for behind the search (structured output)\n",
    "class WebSearchItem(BaseModel):\n",
    "    reason: str\n",
    "    \"Your reasoning for why this search is important to the query.\"\n",
    "    query: str\n",
    "    \"The search term to use for the web search.\"\n",
    "\n",
    "# WebSearchPlan stores the list of web searches to perform to best answer the query (structured output)\n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem]\n",
    "    \"A list of web searches to perform to best answer the query.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5eb8e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = Agent(\n",
    "    name=\"Planner Agent\",\n",
    "    instructions=planner_agent_instructions,\n",
    "    model=gpt_model,\n",
    "    output_type=WebSearchPlan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37c77974",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trace(\"Search\"):\n",
    "    result = await Runner.run(planner_agent, sample_agent_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5076c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "336632b8",
   "metadata": {},
   "source": [
    "## Email Agent\n",
    "* The function will send an email of the summary of the detailed report to my email (kthonnithodi@gmail.com)\n",
    "* The sendgrid api has already been pre configured with the api to my email, however in the future I would like to use any email in the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa0ebee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def send_email(subject: str, html_body: str) -> Dict[str, str]:\n",
    "    sg_instance = sendgrid.SendGridAPIClient(api_key=os.environ.get(\"SENDGRID_API_KEY\"))\n",
    "    from_email = Email(\"kthonnithodi@gmail.com\")\n",
    "    to_email = To(\"kthonnithodi@gmail.com\")\n",
    "    context = Content(\"text/html\", html_body)\n",
    "    mail = Mail(from_email, to_email, subject, context).get()\n",
    "    response = sg_instance.client.mail.send.post(request_body=mail)\n",
    "    return {\"status\": \"success\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e076b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_agent_instructions = (\n",
    "    \"You are able to send a nicely formatted HTML email based on a detailed report.\\n\"\n",
    "    \"You will be provided with a detailed report. You should use your tool to send one email, providing the report converted into clean, well presented HTML with an appropriate subject line.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d65fe179",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_agent = Agent(\n",
    "    name=\"Email Agent\",\n",
    "    instructions=email_agent_instructions,\n",
    "    tools=[send_email],\n",
    "    model=gpt_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff1753a",
   "metadata": {},
   "source": [
    "## Writer Agent\n",
    "* This agent will produce report, given the findings derived from the search agents summary from it's planner agent queries.\n",
    "* Right now the Agentic Workflow would like the following: Planner Agent --> Search Agent --> Writer Agent --> Email Agent (this would handover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988dfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent_instructions_params = {\n",
    "    \"min_paragraph_count\": 5,\n",
    "    \"max_paragraph_count\": 8,\n",
    "    \"min_word_count\": 200,\n",
    "    \"max_word_count\": 300,\n",
    "}\n",
    "\n",
    "writer_agent_instructions = (\n",
    "    f\"You are a senior researcher tasked with writing a cohesive report for a research query. \\\n",
    "    You will be provided with the original query, and some initial research conducted by a research assistant.\\\n",
    "    You should first come up with an outline for the report that describles the structure and flow of the report.\\\n",
    "    Then, generate the reportand return that as your final output.\\\n",
    "    The final output should be in markdown format, and it should be lengthy and detailed.\\\n",
    "    Aim for around {writer_agent_instructions_params[\"min_paragraph_count\"]} - {writer_agent_instructions_params[\"max_paragraph_count\"]} paragraphs.\\\n",
    "    Furthermore, report should consist of {writer_agent_instructions_params[\"min_word_count\"]} - {writer_agent_instructions_params[\"max_word_count\"]} word count.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b60d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The strucuture of the report (summary, then actual report, then follow up questions at the bottom of the report.)\n",
    "class ReportData(BaseModel):\n",
    "    short_summary: str\n",
    "    \"A short 2-3 sentence summary of the findings.\"\n",
    "    markdown_report: str\n",
    "    \"The final report.\"\n",
    "    follow_up_questions: list[str]\n",
    "    \"Suggested topics to research further.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "deb1e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = Agent(\n",
    "    name=\"Writer Agent\",\n",
    "    instructions=writer_agent_instructions,\n",
    "    model=gpt_model,\n",
    "    output_type=ReportData\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc3a3ae",
   "metadata": {},
   "source": [
    "## Functions for planning and execute the search, using planner and search agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18184077",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plan_searches(query: str):\n",
    "    '''\n",
    "    1. The planner agent will return the output of 3 searches (reason and query) based on a topic.\n",
    "    2. The output will show a list of the queries (along with respective reasoning) in the form of a WorkSearchPlan.\n",
    "    '''\n",
    "    result = await Runner.run(planner_agent, f\"Query: {query}\")\n",
    "    return result.final_output\n",
    "\n",
    "async def execute_websearch(item: WebSearchItem):\n",
    "    '''\n",
    "    Use the search agent to run a web search for an instance of the WebSearchItem (one of the queries produced from the plan_searches)\n",
    "    '''\n",
    "    message = f\"Search term: {item.query}\\nReason for searching: {item.reason}\"\n",
    "    result = await Runner.run(search_agent, message)\n",
    "\n",
    "async def execute_websearches(search_plan: WebSearchPlan):\n",
    "    '''\n",
    "    1. Collects the search plan from the plan_searches function call (or the search_plan websearchplan variable)\n",
    "    2. For each query search query in the search plan, create an asyncio task for using a search query. \n",
    "    3. This will scour the internet for each one (in parallel, since they are independant tasks).\n",
    "    4. After creating a co-routine for each, then apply gather for each task in the co-routine to run cocurrently.\n",
    "    5. The end result should be compilation x amount of searches for each query (the summary report for each query generate by the research assistant).\n",
    "    '''\n",
    "    tasks = [asyncio.create_task(execute_websearch(item)) for item in search_plan.searches]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
